
@article{noauthor_notitle_nodate,
}

@inproceedings{bustos_predicting_2021,
	address = {Nara, Japan},
	title = {Predicting {Driver} {Self}-{Reported} {Stress} by {Analyzing} the {Road} {Scene}},
	isbn = {978-1-66540-019-0},
	url = {https://ieeexplore.ieee.org/document/9597438/},
	doi = {10.1109/ACII52823.2021.9597438},
	urldate = {2023-10-24},
	booktitle = {2021 9th {International} {Conference} on {Affective} {Computing} and {Intelligent} {Interaction} ({ACII})},
	publisher = {IEEE},
	author = {Bustos, Cristina and Elhaouij, Neska and Sole-Ribalta, Albert and Borge-Holthoefer, Javier and Lapedriza, Agata and Picard, Rosalind},
	month = sep,
	year = {2021},
	pages = {1--8},
	file = {Submitted Version:C\:\\Users\\Sandra\\Zotero\\storage\\HUH737IV\\Bustos et al. - 2021 - Predicting Driver Self-Reported Stress by Analyzin.pdf:application/pdf},
}

@article{sinex_pulse_1999,
	title = {Pulse oximetry: {Principles} and limitations},
	volume = {17},
	issn = {07356757},
	shorttitle = {Pulse oximetry},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0735675799900190},
	doi = {10.1016/S0735-6757(99)90019-0},
	language = {en},
	number = {1},
	urldate = {2023-10-24},
	journal = {The American Journal of Emergency Medicine},
	author = {Sinex, James E},
	month = jan,
	year = {1999},
	pages = {59--66},
}

@article{rastgoo_critical_2019,
	title = {A {Critical} {Review} of {Proactive} {Detection} of {Driver} {Stress} {Levels} {Based} on {Multimodal} {Measurements}},
	volume = {51},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3186585},
	doi = {10.1145/3186585},
	abstract = {Stress is a major concern in daily life, as it imposes significant and growing health and economic costs on society every year. Stress and driving are a dangerous combination and can lead to life-threatening situations, evidenced by the large number of road traffic crashes that occur every year due to driver stress. In addition, the rate of general health issues caused by work-related chronic stress in drivers who work in public and private transport is greater than in many other occupational groups. An in-vehicle warning system for driver stress levels is needed to continuously predict dangerous driving situations and proactively alert drivers to ensure safe and comfortable driving. As a result of the recent developments in ambient intelligence, such as sensing technologies, pervasive devices, context recognition, and communications, driver stress can be automatically detected using multimodal measurements. This critical review investigates the state of the art of techniques and achievements for automatic driver stress level detection based on multimodal sensors and data. In this work, the most widely used data followed by frequent and highly performed selected features to detect driver stress levels are analyzed and presented. This review also discusses key methodological issues and gaps that hinder the implementation of driver stress detection systems and offers insights into future research directions.},
	language = {en},
	number = {5},
	urldate = {2023-10-24},
	journal = {ACM Computing Surveys},
	author = {Rastgoo, Mohammad Naim and Nakisa, Bahareh and Rakotonirainy, Andry and Chandran, Vinod and Tjondronegoro, Dian},
	month = sep,
	year = {2019},
	pages = {1--35},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\GXGIDQGZ\\Rastgoo et al. - 2019 - A Critical Review of Proactive Detection of Driver.pdf:application/pdf},
}

@inproceedings{he_deep_2016,
	address = {Las Vegas, NV, USA},
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	isbn = {978-1-4673-8851-1},
	url = {http://ieeexplore.ieee.org/document/7780459/},
	doi = {10.1109/CVPR.2016.90},
	urldate = {2023-10-24},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = jun,
	year = {2016},
	pages = {770--778},
	file = {Submitted Version:C\:\\Users\\Sandra\\Zotero\\storage\\EADSHLS3\\He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf:application/pdf},
}

@article{ordonez_deep_2016,
	title = {Deep {Convolutional} and {LSTM} {Recurrent} {Neural} {Networks} for {Multimodal} {Wearable} {Activity} {Recognition}},
	volume = {16},
	issn = {1424-8220},
	url = {http://www.mdpi.com/1424-8220/16/1/115},
	doi = {10.3390/s16010115},
	language = {en},
	number = {1},
	urldate = {2023-10-24},
	journal = {Sensors},
	author = {Ordóñez, Francisco and Roggen, Daniel},
	month = jan,
	year = {2016},
	pages = {115},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\I6FXYAMK\\Ordóñez and Roggen - 2016 - Deep Convolutional and LSTM Recurrent Neural Netwo.pdf:application/pdf},
}

@misc{ioffe_batch_2015,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	shorttitle = {Batch {Normalization}},
	url = {http://arxiv.org/abs/1502.03167},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
	urldate = {2023-10-24},
	publisher = {arXiv},
	author = {Ioffe, Sergey and Szegedy, Christian},
	month = mar,
	year = {2015},
	note = {arXiv:1502.03167 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\3ECK96QR\\Ioffe and Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\UWFC9R7E\\1502.html:text/html},
}

@inproceedings{schmidt_introducing_2018,
	address = {Boulder CO USA},
	title = {Introducing {WESAD}, a {Multimodal} {Dataset} for {Wearable} {Stress} and {Affect} {Detection}},
	isbn = {978-1-4503-5692-3},
	url = {https://dl.acm.org/doi/10.1145/3242969.3242985},
	doi = {10.1145/3242969.3242985},
	language = {en},
	urldate = {2023-10-24},
	booktitle = {Proceedings of the 20th {ACM} {International} {Conference} on {Multimodal} {Interaction}},
	publisher = {ACM},
	author = {Schmidt, Philip and Reiss, Attila and Duerichen, Robert and Marberger, Claus and Van Laerhoven, Kristof},
	month = oct,
	year = {2018},
	pages = {400--408},
}

@inproceedings{haouij_affectiveroad_2018,
	address = {Pau France},
	title = {{AffectiveROAD} system and database to assess driver's attention},
	isbn = {978-1-4503-5191-1},
	url = {https://dl.acm.org/doi/10.1145/3167132.3167395},
	doi = {10.1145/3167132.3167395},
	language = {en},
	urldate = {2023-10-24},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Symposium} on {Applied} {Computing}},
	publisher = {ACM},
	author = {Haouij, Neska El and Poggi, Jean-Michel and Sevestre-Ghalila, Sylvie and Ghozi, Raja and Jaïdane, Mériem},
	month = apr,
	year = {2018},
	pages = {800--803},
}

@misc{juae_realizations_2021,
	title = {Realizations of automorphism groups of metric graphs induced by rational maps},
	url = {http://arxiv.org/abs/2103.00174},
	abstract = {For a rational map \${\textbackslash}phi\$ from a metric graph \${\textbackslash}varGamma\$ to a tropical projective space \${\textbackslash}boldsymbol\{TP{\textasciicircum}n\}\$ defined by a ratio of rational functions \$f\_1, {\textbackslash}ldots, f\_\{n + 1\}\$, an automorphism \${\textbackslash}sigma\$ of \${\textbackslash}varGamma\$ induces a permutation of the coordinates of \${\textbackslash}boldsymbol\{TP{\textasciicircum}n\}\$ if \${\textbackslash}\{ f\_1, {\textbackslash}ldots, f\_\{n + 1\} {\textbackslash}\}\$ is \${\textbackslash}langle {\textbackslash}sigma {\textbackslash}rangle\$-invariant. Through this description, we can realize the automorphism group of \${\textbackslash}Gamma\$ as ambient automorphism group such as tropical projective general linear group, tropical general linear group and \${\textbackslash}boldsymbol\{Z\}\$-linear transformation group of Euclidean space.},
	urldate = {2023-10-25},
	publisher = {arXiv},
	author = {JuAe, Song},
	month = feb,
	year = {2021},
	note = {arXiv:2103.0174 null},
	keywords = {Mathematics - Algebraic Geometry, Mathematics - Combinatorics},
	annote = {Comment: 14 pages},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\H4LBUEEM\\JuAe - 2021 - Realizations of automorphism groups of metric grap.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\KQWUVAFD\\2103.html:text/html},
}

@article{bieder_comparison_2021,
	title = {Comparison of {Methods} {Generalizing} {Max}- and {Average}-{Pooling}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2103.01746},
	doi = {10.48550/ARXIV.2103.01746},
	abstract = {Max- and average-pooling are the most popular pooling methods for downsampling in convolutional neural networks. In this paper, we compare different pooling methods that generalize both max- and average-pooling. Furthermore, we propose another method based on a smooth approximation of the maximum function and put it into context with related methods. For the comparison, we use a VGG16 image classification network and train it on a large dataset of natural high-resolution images (Google Open Images v5). The results show that none of the more sophisticated methods perform significantly better in this classification task than standard max- or average-pooling.},
	urldate = {2023-10-25},
	author = {Bieder, Florentin and Sandkühler, Robin and Cattin, Philippe C.},
	year = {2021},
	note = {Publisher: arXiv
Version Number: 1},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, Machine Learning (cs.LG)},
	annote = {Other
16 pages, 6 figures},
}

@article{alzubaidi_review_2021,
	title = {Review of deep learning: concepts, {CNN} architectures, challenges, applications, future directions},
	volume = {8},
	issn = {2196-1115},
	shorttitle = {Review of deep learning},
	url = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00444-8},
	doi = {10.1186/s40537-021-00444-8},
	abstract = {Abstract
            In the last few years, the deep learning (DL) computing paradigm has been deemed the Gold Standard in the machine learning (ML) community. Moreover, it has gradually become the most widely used computational approach in the field of ML, thus achieving outstanding results on several complex cognitive tasks, matching or even beating those provided by human performance. One of the benefits of DL is the ability to learn massive amounts of data. The DL field has grown fast in the last few years and it has been extensively used to successfully address a wide range of traditional applications. More importantly, DL has outperformed well-known ML techniques in many domains, e.g., cybersecurity, natural language processing, bioinformatics, robotics and control, and medical information processing, among many others. Despite it has been contributed several works reviewing the State-of-the-Art on DL, all of them only tackled one aspect of the DL, which leads to an overall lack of knowledge about it. Therefore, in this contribution, we propose using a more holistic approach in order to provide a more suitable starting point from which to develop a full understanding of DL. Specifically, this review attempts to provide a more comprehensive survey of the most important aspects of DL and including those enhancements recently added to the field. In particular, this paper outlines the importance of DL, presents the types of DL techniques and networks. It then presents convolutional neural networks (CNNs) which the most utilized DL network type and describes the development of CNNs architectures together with their main features, e.g., starting with the AlexNet network and closing with the High-Resolution network (HR.Net). Finally, we further present the challenges and suggested solutions to help researchers understand the existing research gaps. It is followed by a list of the major DL applications. Computational tools including FPGA, GPU, and CPU are summarized along with a description of their influence on DL. The paper ends with the evolution matrix, benchmark datasets, and summary and conclusion.},
	language = {en},
	number = {1},
	urldate = {2023-10-25},
	journal = {Journal of Big Data},
	author = {Alzubaidi, Laith and Zhang, Jinglan and Humaidi, Amjad J. and Al-Dujaili, Ayad and Duan, Ye and Al-Shamma, Omran and Santamaría, J. and Fadhel, Mohammed A. and Al-Amidie, Muthana and Farhan, Laith},
	month = mar,
	year = {2021},
	pages = {53},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\H8FHPK5L\\Alzubaidi et al. - 2021 - Review of deep learning concepts, CNN architectur.pdf:application/pdf},
}

@article{dissanayake_sigrep_2022,
	title = {{SigRep}: {Toward} {Robust} {Wearable} {Emotion} {Recognition} {With} {Contrastive} {Representation} {Learning}},
	volume = {10},
	issn = {2169-3536},
	shorttitle = {{SigRep}},
	url = {https://ieeexplore.ieee.org/document/9706192/},
	doi = {10.1109/ACCESS.2022.3149509},
	urldate = {2023-10-26},
	journal = {IEEE Access},
	author = {Dissanayake, Vipula and Seneviratne, Sachith and Rana, Rajib and Wen, Elliott and Kaluarachchi, Tharindu and Nanayakkara, Suranga},
	year = {2022},
	pages = {18105--18120},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\T6QCTY4H\\Dissanayake et al. - 2022 - SigRep Toward Robust Wearable Emotion Recognition.pdf:application/pdf},
}

@misc{szegedy_going_2014,
	title = {Going {Deeper} with {Convolutions}},
	url = {http://arxiv.org/abs/1409.4842},
	abstract = {We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
	urldate = {2023-10-26},
	publisher = {arXiv},
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	month = sep,
	year = {2014},
	note = {arXiv:1409.4842 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\YGW4NIZ8\\Szegedy et al. - 2014 - Going Deeper with Convolutions.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\7KHLMBEX\\1409.html:text/html},
}

@misc{ninh_improved_2022,
	title = {An {Improved} {Subject}-{Independent} {Stress} {Detection} {Model} {Applied} to {Consumer}-grade {Wearable} {Devices}},
	url = {http://arxiv.org/abs/2203.09663},
	abstract = {Stress is a complex issue with wide-ranging physical and psychological impacts on human daily performance. Specifically, acute stress detection is becoming a valuable application in contextual human understanding. Two common approaches to training a stress detection model are subject-dependent and subject-independent training methods. Although subject-dependent training methods have proven to be the most accurate approach to build stress detection models, subject-independent models are a more practical and cost-efficient method, as they allow for the deployment of stress level detection and management systems in consumer-grade wearable devices without requiring training data for the end-user. To improve the performance of subject-independent stress detection models, in this paper, we introduce a stress-related bio-signal processing pipeline with a simple neural network architecture using statistical features extracted from multimodal contextual sensing sources including Electrodermal Activity (EDA), Blood Volume Pulse (BVP), and Skin Temperature (ST) captured from a consumer-grade wearable device. Using our proposed model architecture, we compare the accuracy between stress detection models that use measures from each individual signal source, and one model employing the fusion of multiple sensor sources. Extensive experiments on the publicly available WESAD dataset demonstrate that our proposed model outperforms conventional methods as well as providing 1.63\% higher mean accuracy score compared to the state-of-the-art model while maintaining a low standard deviation. Our experiments also show that combining features from multiple sources produce more accurate predictions than using only one sensor source individually.},
	urldate = {2023-10-26},
	publisher = {arXiv},
	author = {Ninh, Van-Tu and Nguyen, Manh-Duy and Smyth, Sinéad and Tran, Minh-Triet and Healy, Graham and Nguyen, Binh T. and Gurrin, Cathal},
	month = mar,
	year = {2022},
	note = {arXiv:2203.09663 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\YERMVP4V\\Ninh et al. - 2022 - An Improved Subject-Independent Stress Detection M.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\P4F5JFFC\\2203.html:text/html},
}

@article{li_stress_2020,
	title = {Stress detection using deep neural networks},
	volume = {20},
	issn = {1472-6947},
	url = {https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-020-01299-4},
	doi = {10.1186/s12911-020-01299-4},
	abstract = {Abstract
            
              Background
              Over 70\% of Americans regularly experience stress. Chronic stress results in cancer, cardiovascular disease, depression, and diabetes, and thus is deeply detrimental to physiological health and psychological wellbeing. Developing robust methods for the rapid and accurate detection of human stress is of paramount importance.
            
            
              Methods
              Prior research has shown that analyzing physiological signals is a reliable predictor of stress. Such signals are collected from sensors that are attached to the human body. Researchers have attempted to detect stress by using traditional machine learning methods to analyze physiological signals. Results, ranging between 50 and 90\% accuracy, have been mixed. A limitation of traditional machine learning algorithms is the requirement for hand-crafted features. Accuracy decreases if features are misidentified. To address this deficiency, we developed two deep neural networks: a 1-dimensional (1D) convolutional neural network and a multilayer perceptron neural network. Deep neural networks do not require hand-crafted features but instead extract features from raw data through the layers of the neural networks. The deep neural networks analyzed physiological data collected from chest-worn and wrist-worn sensors to perform two tasks. We tailored each neural network to analyze data from either the chest-worn (1D convolutional neural network) or wrist-worn (multilayer perceptron neural network) sensors. The first task was binary classification for stress detection, in which the networks differentiated between stressed and non-stressed states. The second task was 3-class classification for emotion classification, in which the networks differentiated between baseline, stressed, and amused states. The networks were trained and tested on publicly available data collected in previous studies.
            
            
              Results
              The deep convolutional neural network achieved 99.80\% and 99.55\% accuracy rates for binary and 3-class classification, respectively. The deep multilayer perceptron neural network achieved 99.65\% and 98.38\% accuracy rates for binary and 3-class classification, respectively. The networks’ performance exhibited a significant improvement over past methods that analyzed physiological signals for both binary stress detection and 3-class emotion classification.
            
            
              Conclusions
              We demonstrated the potential of deep neural networks for developing robust, continuous, and noninvasive methods for stress detection and emotion classification, with the end goal of improving the quality of life.},
	language = {en},
	number = {S11},
	urldate = {2023-10-26},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Li, Russell and Liu, Zhandong},
	month = dec,
	year = {2020},
	pages = {285},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\856LUPFY\\Li and Liu - 2020 - Stress detection using deep neural networks.pdf:application/pdf},
}

@inproceedings{siirtola_continuous_2019,
	address = {London United Kingdom},
	title = {Continuous stress detection using the sensors of commercial smartwatch},
	isbn = {978-1-4503-6869-8},
	url = {https://dl.acm.org/doi/10.1145/3341162.3344831},
	doi = {10.1145/3341162.3344831},
	language = {en},
	urldate = {2023-10-26},
	booktitle = {Adjunct {Proceedings} of the 2019 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing} and {Proceedings} of the 2019 {ACM} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {ACM},
	author = {Siirtola, Pekka},
	month = sep,
	year = {2019},
	pages = {1198--1201},
}

@article{amin_real-world_2023,
	title = {Real-{World} {Driver} {Stress} {Recognition} and {Diagnosis} {Based} on {Multimodal} {Deep} {Learning} and {Fuzzy} {EDAS} {Approaches}},
	volume = {13},
	issn = {2075-4418},
	url = {https://www.mdpi.com/2075-4418/13/11/1897},
	doi = {10.3390/diagnostics13111897},
	abstract = {Mental stress is known as a prime factor in road crashes. The devastation of these crashes often results in damage to humans, vehicles, and infrastructure. Likewise, persistent mental stress could lead to the development of mental, cardiovascular, and abdominal disorders. Preceding research in this domain mostly focuses on feature engineering and conventional machine learning approaches. These approaches recognize different levels of stress based on handcrafted features extracted from various modalities including physiological, physical, and contextual data. Acquiring good quality features from these modalities using feature engineering is often a difficult job. Recent developments in the form of deep learning (DL) algorithms have relieved feature engineering by automatically extracting and learning resilient features. This paper proposes different CNN and CNN-LSTSM-based fusion models using physiological signals (SRAD dataset) and multimodal data (AffectiveROAD dataset) for the driver’s two and three stress levels. The fuzzy EDAS (evaluation based on distance from average solution) approach is used to evaluate the performance of the proposed models based on different classification metrics (accuracy, recall, precision, F-score, and specificity). Fuzzy EDAS performance estimation shows that the proposed CNN and hybrid CNN-LSTM models achieved the first ranks based on the fusion of BH, E4-Left (E4-L), and E4-Right (E4-R). Results showed the significance of multimodal data for designing an accurate and trustworthy stress recognition diagnosing model for real-world driving conditions. The proposed model can also be used for the diagnosis of the stress level of a subject during other daily life activities.},
	language = {en},
	number = {11},
	urldate = {2023-10-26},
	journal = {Diagnostics},
	author = {Amin, Muhammad and Ullah, Khalil and Asif, Muhammad and Shah, Habib and Mehmood, Arshad and Khan, Muhammad Attique},
	month = may,
	year = {2023},
	pages = {1897},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\JPYXHGMM\\Amin et al. - 2023 - Real-World Driver Stress Recognition and Diagnosis.pdf:application/pdf},
}

@article{siirtola_comparison_2020,
	title = {Comparison of {Regression} and {Classification} {Models} for {User}-{Independent} and {Personal} {Stress} {Detection}},
	volume = {20},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/16/4402},
	doi = {10.3390/s20164402},
	abstract = {In this article, regression and classification models are compared for stress detection. Both personal and user-independent models are experimented. The article is based on publicly open dataset called AffectiveROAD, which contains data gathered using Empatica E4 sensor and unlike most of the other stress detection datasets, it contains continuous target variables. The used classification model is Random Forest and the regression model is Bagged tree based ensemble. Based on experiments, regression models outperform classification models, when classifying observations as stressed or not-stressed. The best user-independent results are obtained using a combination of blood volume pulse and skin temperature features, and using these the average balanced accuracy was 74.1\% with classification model and 82.3\% using regression model. In addition, regression models can be used to estimate the level of the stress. Moreover, the results based on models trained using personal data are not encouraging showing that biosignals have a lot of variation not only between the study subjects but also between the session gathered from the same person. On the other hand, it is shown that with subject-wise feature selection for user-independent model, it is possible to improve recognition models more than by using personal training data to build personal models. In fact, it is shown that with subject-wise feature selection, the average detection rate can be improved as much as 4\%-units, and it is especially useful to reduce the variance in the recognition rates between the study subjects.},
	language = {en},
	number = {16},
	urldate = {2023-10-26},
	journal = {Sensors},
	author = {Siirtola, Pekka and Röning, Juha},
	month = aug,
	year = {2020},
	pages = {4402},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\J8A3AP28\\Siirtola and Röning - 2020 - Comparison of Regression and Classification Models.pdf:application/pdf},
}

@misc{lopez-martinez_detection_2019,
	title = {Detection of {Real}-world {Driving}-induced {Affective} {State} {Using} {Physiological} {Signals} and {Multi}-view {Multi}-task {Machine} {Learning}},
	url = {http://arxiv.org/abs/1907.09929},
	abstract = {Affective states have a critical role in driving performance and safety. They can degrade driver situation awareness and negatively impact cognitive processes, severely diminishing road safety. Therefore, detecting and assessing drivers' affective states is crucial in order to help improve the driving experience, and increase safety, comfort and well-being. Recent advances in affective computing have enabled the detection of such states. This may lead to empathic automotive user interfaces that account for the driver's emotional state and influence the driver in order to improve safety. In this work, we propose a multiview multi-task machine learning method for the detection of driver's affective states using physiological signals. The proposed approach is able to account for inter-drive variability in physiological responses while enabling interpretability of the learned models, a factor that is especially important in systems deployed in the real world. We evaluate the models on three different datasets containing real-world driving experiences. Our results indicate that accounting for drive-specific differences significantly improves model performance.},
	urldate = {2023-10-28},
	publisher = {arXiv},
	author = {Lopez-Martinez, Daniel and El-Haouij, Neska and Picard, Rosalind},
	month = jul,
	year = {2019},
	note = {arXiv:1907.09929 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Affective Computing and Intelligent Interaction Conference 2019},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\5DNWNIHG\\Lopez-Martinez et al. - 2019 - Detection of Real-world Driving-induced Affective .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\YNDVU2ML\\1907.html:text/html},
}

@article{canizo_multi-head_2019,
	title = {Multi-head {CNN}–{RNN} for multi-time series anomaly detection: {An} industrial case study},
	volume = {363},
	issn = {09252312},
	shorttitle = {Multi-head {CNN}–{RNN} for multi-time series anomaly detection},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231219309877},
	doi = {10.1016/j.neucom.2019.07.034},
	language = {en},
	urldate = {2023-11-05},
	journal = {Neurocomputing},
	author = {Canizo, Mikel and Triguero, Isaac and Conde, Angel and Onieva, Enrique},
	month = oct,
	year = {2019},
	pages = {246--260},
}

@misc{foumani_deep_2023,
	title = {Deep {Learning} for {Time} {Series} {Classification} and {Extrinsic} {Regression}: {A} {Current} {Survey}},
	shorttitle = {Deep {Learning} for {Time} {Series} {Classification} and {Extrinsic} {Regression}},
	url = {http://arxiv.org/abs/2302.02515},
	abstract = {Time Series Classification and Extrinsic Regression are important and challenging machine learning tasks. Deep learning has revolutionized natural language processing and computer vision and holds great promise in other fields such as time series analysis where the relevant features must often be abstracted from the raw data but are not known a priori. This paper surveys the current state of the art in the fast-moving field of deep learning for time series classification and extrinsic regression. We review different network architectures and training methods used for these tasks and discuss the challenges and opportunities when applying deep learning to time series data. We also summarize two critical applications of time series classification and extrinsic regression, human activity recognition and satellite earth observation.},
	publisher = {arXiv},
	author = {Foumani, Navid Mohammadi and Miller, Lynn and Tan, Chang Wei and Webb, Geoffrey I. and Forestier, Germain and Salehi, Mahsa},
	month = feb,
	year = {2023},
	note = {arXiv:2302.02515 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\5932GL8U\\Foumani et al. - 2023 - Deep Learning for Time Series Classification and E.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\7DNM6AUP\\2302.html:text/html},
}

@misc{vaswani_attention_2023,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2023-11-05},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = aug,
	year = {2023},
	note = {arXiv:1706.03762 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	annote = {Comment: 15 pages, 5 figures},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\DD5PRRT9\\Vaswani et al. - 2023 - Attention Is All You Need.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\4IT7CJVF\\1706.html:text/html},
}

@misc{pascanu_difficulty_2013,
	title = {On the difficulty of training {Recurrent} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1211.5063},
	abstract = {There are two widely known issues with properly training Recurrent Neural Networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.},
	publisher = {arXiv},
	author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
	month = feb,
	year = {2013},
	note = {arXiv:1211.5063 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Improved description of the exploding gradient problem and description and analysis of the vanishing gradient problem},
	annote = {Comment: Improved description of the exploding gradient problem and description and analysis of the vanishing gradient problem},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\43M5AM4W\\Pascanu et al. - 2013 - On the difficulty of training Recurrent Neural Net.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\LK3E4JKF\\1211.html:text/html},
}

@article{krizhevsky_imagenet_2017,
	title = {{ImageNet} classification with deep convolutional neural networks},
	volume = {60},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3065386},
	doi = {10.1145/3065386},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
	language = {en},
	number = {6},
	urldate = {2023-11-18},
	journal = {Communications of the ACM},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	month = may,
	year = {2017},
	pages = {84--90},
	file = {Submitted Version:C\:\\Users\\Sandra\\Zotero\\storage\\KEW4SNC8\\Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf:application/pdf},
}

@misc{otter_survey_2019,
	title = {A {Survey} of the {Usages} of {Deep} {Learning} in {Natural} {Language} {Processing}},
	url = {http://arxiv.org/abs/1807.10854},
	abstract = {Over the last several years, the field of natural language processing has been propelled forward by an explosion in the use of deep learning models. This survey provides a brief introduction to the field and a quick overview of deep learning architectures and methods. It then sifts through the plethora of recent studies and summarizes a large assortment of relevant contributions. Analyzed research areas include several core linguistic processing issues in addition to a number of applications of computational linguistics. A discussion of the current state of the art is then provided along with recommendations for future research in the field.},
	urldate = {2023-11-18},
	publisher = {arXiv},
	author = {Otter, Daniel W. and Medina, Julian R. and Kalita, Jugal K.},
	month = dec,
	year = {2019},
	note = {arXiv:1807.10854 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\RGP4LWD3\\Otter et al. - 2019 - A Survey of the Usages of Deep Learning in Natural.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\G4PKMAVZ\\1807.html:text/html},
}

@article{hewamalage_recurrent_2021,
	title = {Recurrent {Neural} {Networks} for {Time} {Series} {Forecasting}: {Current} {Status} and {Future} {Directions}},
	volume = {37},
	issn = {01692070},
	shorttitle = {Recurrent {Neural} {Networks} for {Time} {Series} {Forecasting}},
	url = {http://arxiv.org/abs/1909.00590},
	doi = {10.1016/j.ijforecast.2020.06.008},
	abstract = {Recurrent Neural Networks (RNN) have become competitive forecasting methods, as most notably shown in the winning method of the recent M4 competition. However, established statistical models such as ETS and ARIMA gain their popularity not only from their high accuracy, but they are also suitable for non-expert users as they are robust, efficient, and automatic. In these areas, RNNs have still a long way to go. We present an extensive empirical study and an open-source software framework of existing RNN architectures for forecasting, that allow us to develop guidelines and best practices for their use. For example, we conclude that RNNs are capable of modelling seasonality directly if the series in the dataset possess homogeneous seasonal patterns, otherwise we recommend a deseasonalization step. Comparisons against ETS and ARIMA demonstrate that the implemented (semi-)automatic RNN models are no silver bullets, but they are competitive alternatives in many situations.},
	number = {1},
	urldate = {2023-11-18},
	journal = {International Journal of Forecasting},
	author = {Hewamalage, Hansika and Bergmeir, Christoph and Bandara, Kasun},
	month = jan,
	year = {2021},
	note = {arXiv:1909.00590 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	pages = {388--427},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\9NEX7UC2\\Hewamalage et al. - 2021 - Recurrent Neural Networks for Time Series Forecast.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\C423EZ53\\1909.html:text/html},
}

@article{fawaz_inceptiontime_2020,
	title = {{InceptionTime}: {Finding} {AlexNet} for {Time} {Series} {Classification}},
	volume = {34},
	issn = {1384-5810, 1573-756X},
	shorttitle = {{InceptionTime}},
	url = {http://arxiv.org/abs/1909.04939},
	doi = {10.1007/s10618-020-00710-y},
	abstract = {This paper brings deep learning at the forefront of research into Time Series Classification (TSC). TSC is the area of machine learning tasked with the categorization (or labelling) of time series. The last few decades of work in this area have led to significant progress in the accuracy of classifiers, with the state of the art now represented by the HIVE-COTE algorithm. While extremely accurate, HIVE-COTE cannot be applied to many real-world datasets because of its high training time complexity in O(N2 * T4) for a dataset with N time series of length T. For example, it takes HIVE-COTE more than 8 days to learn from a small dataset with N = 1500 time series of short length T = 46. Meanwhile deep learning has received enormous attention because of its high accuracy and scalability. Recent approaches to deep learning for TSC have been scalable, but less accurate than HIVE-COTE. We introduce InceptionTime - an ensemble of deep Convolutional Neural Network (CNN) models, inspired by the Inception-v4 architecture. Our experiments show that InceptionTime is on par with HIVE-COTE in terms of accuracy while being much more scalable: not only can it learn from 1,500 time series in one hour but it can also learn from 8M time series in 13 hours, a quantity of data that is fully out of reach of HIVE-COTE.},
	number = {6},
	urldate = {2023-11-23},
	journal = {Data Mining and Knowledge Discovery},
	author = {Fawaz, Hassan Ismail and Lucas, Benjamin and Forestier, Germain and Pelletier, Charlotte and Schmidt, Daniel F. and Weber, Jonathan and Webb, Geoffrey I. and Idoumghar, Lhassane and Muller, Pierre-Alain and Petitjean, François},
	month = nov,
	year = {2020},
	note = {arXiv:1909.04939 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {1936--1962},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\79MQUMF8\\Fawaz et al. - 2020 - InceptionTime Finding AlexNet for Time Series Cla.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\RF7V74NQ\\1909.html:text/html},
}

@article{vos_generalizable_2023,
	title = {Generalizable machine learning for stress monitoring from wearable devices: {A} systematic literature review},
	volume = {173},
	issn = {13865056},
	shorttitle = {Generalizable machine learning for stress monitoring from wearable devices},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1386505623000436},
	doi = {10.1016/j.ijmedinf.2023.105026},
	language = {en},
	urldate = {2023-11-25},
	journal = {International Journal of Medical Informatics},
	author = {Vos, Gideon and Trinh, Kelly and Sarnyai, Zoltan and Rahimi Azghadi, Mostafa},
	month = may,
	year = {2023},
	pages = {105026},
	file = {Accepted Version:C\:\\Users\\Sandra\\Zotero\\storage\\M6ZIBNAS\\Vos et al. - 2023 - Generalizable machine learning for stress monitori.pdf:application/pdf},
}

@article{avramidis_multimodal_2022,
	title = {Multimodal {Estimation} of {Change} {Points} of {Physiological} {Arousal} in {Drivers}},
	url = {http://arxiv.org/abs/2210.15826},
	abstract = {Detecting unsafe driving states, such as stress, drowsiness, and fatigue, is an important component of ensuring driving safety and an essential prerequisite for automatic intervention systems in vehicles. These concerning conditions are primarily connected to the driver's low or high arousal levels. In this study, we describe a framework for processing multimodal physiological time-series from wearable sensors during driving and locating points of prominent change in drivers' physiological arousal state. These points of change could potentially indicate events that require just-in-time intervention. We apply time-series segmentation on heart rate and breathing rate measurements and quantify their robustness in capturing change points in electrodermal activity, treated as a reference index for arousal, as well as on self-reported stress ratings, using three public datasets. Our experiments demonstrate that physiological measures are veritable indicators of change points of arousal and perform robustly across an extensive ablation study.},
	urldate = {2023-11-25},
	author = {Avramidis, Kleanthis and Feng, Tiantian and Bose, Digbalay and Narayanan, Shrikanth},
	month = oct,
	year = {2022},
	note = {arXiv:2210.15826 [cs, eess]},
	keywords = {Computer Science - Human-Computer Interaction, Electrical Engineering and Systems Science - Signal Processing},
	annote = {Comment: 5 pages, 3 tables, 4 figures},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\8923947E\\Avramidis et al. - 2022 - Multimodal Estimation of Change Points of Physiolo.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\7G6R9H99\\2210.html:text/html},
}

@incollection{mejia-mejia_photoplethysmography_2022,
	title = {Photoplethysmography signal processing and synthesis},
	isbn = {978-0-12-823374-0},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128233740000153},
	language = {en},
	urldate = {2023-11-25},
	booktitle = {Photoplethysmography},
	publisher = {Elsevier},
	author = {Mejía-Mejía, Elisa and Allen, John and Budidha, Karthik and El-Hajj, Chadi and Kyriacou, Panicos A. and Charlton, Peter H.},
	year = {2022},
	doi = {10.1016/B978-0-12-823374-0.00015-3},
	pages = {69--146},
}

@article{nemcova_multimodal_2021,
	title = {Multimodal {Features} for {Detection} of {Driver} {Stress} and {Fatigue}: {Review}},
	volume = {22},
	issn = {1524-9050, 1558-0016},
	shorttitle = {Multimodal {Features} for {Detection} of {Driver} {Stress} and {Fatigue}},
	url = {https://ieeexplore.ieee.org/document/9031734/},
	doi = {10.1109/TITS.2020.2977762},
	number = {6},
	urldate = {2023-11-26},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Nemcova, Andrea and Svozilova, Veronika and Bucsuhazy, Katerina and Smisek, Radovan and Mezl, Martin and Hesko, Branislav and Belak, Michal and Bilik, Martin and Maxera, Pavel and Seitl, Martin and Dominik, Tomas and Semela, Marek and Sucha, Matus and Kolar, Radim},
	month = jun,
	year = {2021},
	pages = {3214--3233},
	file = {Accepted Version:C\:\\Users\\Sandra\\Zotero\\storage\\B5BHPGMA\\Nemcova et al. - 2021 - Multimodal Features for Detection of Driver Stress.pdf:application/pdf},
}

@incollection{huang_introduction_2019,
	address = {Singapore},
	title = {Introduction to {Educational} {Technology}},
	isbn = {9789811366420 9789811366437},
	url = {http://link.springer.com/10.1007/978-981-13-6643-7_1},
	language = {en},
	urldate = {2023-12-01},
	booktitle = {Educational {Technology}},
	publisher = {Springer Singapore},
	author = {Huang, Ronghuai and Spector, J. Michael and Yang, Junfeng},
	collaborator = {Huang, Ronghuai and Spector, J. Michael and Yang, Junfeng},
	year = {2019},
	doi = {10.1007/978-981-13-6643-7_1},
	note = {Series Title: Lecture Notes in Educational Technology},
	pages = {3--31},
}

@article{noauthor_notitle_nodate-1,
}

@article{carstens_effects_2021,
	title = {Effects of {Technology} on {Student} {Learning}},
	author = {Carstens, Kaite J. and Mallon, Jamie M. and Bataineh, Mohamed and Al-Bataineh, Adel},
	year = {2021},
}

@article{hochreiter_long_1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667, 1530-888X},
	url = {https://direct.mit.edu/neco/article/9/8/1735-1780/6109},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	language = {en},
	number = {8},
	urldate = {2023-12-06},
	journal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	month = nov,
	year = {1997},
	pages = {1735--1780},
}

@misc{xie_aggregated_2017,
	title = {Aggregated {Residual} {Transformations} for {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1611.05431},
	abstract = {We present a simple, highly modularized network architecture for image classification. Our network is constructed by repeating a building block that aggregates a set of transformations with the same topology. Our simple design results in a homogeneous, multi-branch architecture that has only a few hyper-parameters to set. This strategy exposes a new dimension, which we call "cardinality" (the size of the set of transformations), as an essential factor in addition to the dimensions of depth and width. On the ImageNet-1K dataset, we empirically show that even under the restricted condition of maintaining complexity, increasing cardinality is able to improve classification accuracy. Moreover, increasing cardinality is more effective than going deeper or wider when we increase the capacity. Our models, named ResNeXt, are the foundations of our entry to the ILSVRC 2016 classification task in which we secured 2nd place. We further investigate ResNeXt on an ImageNet-5K set and the COCO detection set, also showing better results than its ResNet counterpart. The code and models are publicly available online.},
	urldate = {2023-12-06},
	publisher = {arXiv},
	author = {Xie, Saining and Girshick, Ross and Dollár, Piotr and Tu, Zhuowen and He, Kaiming},
	month = apr,
	year = {2017},
	note = {arXiv:1611.05431 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Accepted to CVPR 2017. Code and models: https://github.com/facebookresearch/ResNeXt},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\P66AVRW2\\Xie et al. - 2017 - Aggregated Residual Transformations for Deep Neura.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\PPXUV3MG\\1611.html:text/html},
}

@article{hochreiter_long_1997-1,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667, 1530-888X},
	url = {https://direct.mit.edu/neco/article/9/8/1735-1780/6109},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	language = {en},
	number = {8},
	urldate = {2023-12-18},
	journal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	month = nov,
	year = {1997},
	pages = {1735--1780},
}

@misc{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2023-12-18},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv:1412.6980 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015},
	file = {arXiv Fulltext PDF:C\:\\Users\\Sandra\\Zotero\\storage\\S6N673Y2\\Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sandra\\Zotero\\storage\\BELWVHID\\1412.html:text/html},
}

@incollection{susto_time-series_2018,
	title = {Time-{Series} {Classification} {Methods}: {Review} and {Applications} to {Power} {Systems} {Data}},
	isbn = {978-0-12-811968-6},
	shorttitle = {Time-{Series} {Classification} {Methods}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128119686000097},
	language = {en},
	urldate = {2023-12-18},
	booktitle = {Big {Data} {Application} in {Power} {Systems}},
	publisher = {Elsevier},
	author = {Susto, Gian Antonio and Cenedese, Angelo and Terzi, Matteo},
	year = {2018},
	doi = {10.1016/B978-0-12-811968-6.00009-7},
	pages = {179--220},
}

@incollection{cartwright_machine_2021,
	address = {New York, NY},
	title = {Machine {Learning} for {Biomedical} {Time} {Series} {Classification}: {From} {Shapelets} to {Deep} {Learning}},
	volume = {2190},
	isbn = {978-1-07-160825-8 978-1-07-160826-5},
	shorttitle = {Machine {Learning} for {Biomedical} {Time} {Series} {Classification}},
	url = {https://link.springer.com/10.1007/978-1-0716-0826-5_2},
	language = {en},
	urldate = {2023-12-18},
	booktitle = {Artificial {Neural} {Networks}},
	publisher = {Springer US},
	author = {Bock, Christian and Moor, Michael and Jutzeler, Catherine R. and Borgwardt, Karsten},
	editor = {Cartwright, Hugh},
	year = {2021},
	doi = {10.1007/978-1-0716-0826-5_2},
	note = {Series Title: Methods in Molecular Biology},
	pages = {33--71},
}

@article{wang_systematic_2022,
	title = {A {Systematic} {Review} of {Time} {Series} {Classification} {Techniques} {Used} in {Biomedical} {Applications}},
	volume = {22},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/20/8016},
	doi = {10.3390/s22208016},
	abstract = {Background: Digital clinical measures collected via various digital sensing technologies such as smartphones, smartwatches, wearables, and ingestible and implantable sensors are increasingly used by individuals and clinicians to capture the health outcomes or behavioral and physiological characteristics of individuals. Time series classification (TSC) is very commonly used for modeling digital clinical measures. While deep learning models for TSC are very common and powerful, there exist some fundamental challenges. This review presents the non-deep learning models that are commonly used for time series classification in biomedical applications that can achieve high performance. Objective: We performed a systematic review to characterize the techniques that are used in time series classification of digital clinical measures throughout all the stages of data processing and model building. Methods: We conducted a literature search on PubMed, as well as the Institute of Electrical and Electronics Engineers (IEEE), Web of Science, and SCOPUS databases using a range of search terms to retrieve peer-reviewed articles that report on the academic research about digital clinical measures from a five-year period between June 2016 and June 2021. We identified and categorized the research studies based on the types of classification algorithms and sensor input types. Results: We found 452 papers in total from four different databases: PubMed, IEEE, Web of Science Database, and SCOPUS. After removing duplicates and irrelevant papers, 135 articles remained for detailed review and data extraction. Among these, engineered features using time series methods that were subsequently fed into widely used machine learning classifiers were the most commonly used technique, and also most frequently achieved the best performance metrics (77 out of 135 articles). Statistical modeling (24 out of 135 articles) algorithms were the second most common and also the second-best classification technique. Conclusions: In this review paper, summaries of the time series classification models and interpretation methods for biomedical applications are summarized and categorized. While high time series classification performance has been achieved in digital clinical, physiological, or biomedical measures, no standard benchmark datasets, modeling methods, or reporting methodology exist. There is no single widely used method for time series model development or feature interpretation, however many different methods have proven successful.},
	language = {en},
	number = {20},
	urldate = {2023-12-18},
	journal = {Sensors},
	author = {Wang, Will Ke and Chen, Ina and Hershkovich, Leeor and Yang, Jiamu and Shetty, Ayush and Singh, Geetika and Jiang, Yihang and Kotla, Aditya and Shang, Jason Zisheng and Yerrabelli, Rushil and Roghanizad, Ali R. and Shandhi, Md Mobashir Hasan and Dunn, Jessilyn},
	month = oct,
	year = {2022},
	pages = {8016},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\BX5QBBB4\\Wang et al. - 2022 - A Systematic Review of Time Series Classification .pdf:application/pdf},
}

@article{sun_classification_2009,
	title = {Classification of imbalanced data: a review},
	volume = {23},
	issn = {0218-0014, 1793-6381},
	shorttitle = {{CLASSIFICATION} {OF} {IMBALANCED} {DATA}},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S0218001409007326},
	doi = {10.1142/S0218001409007326},
	abstract = {Classification of data with imbalanced class distribution has encountered a significant drawback of the performance attainable by most standard classifier learning algorithms which assume a relatively balanced class distribution and equal misclassification costs. This paper provides a review of the classification of imbalanced data regarding: the application domains; the nature of the problem; the learning difficulties with standard classifier learning algorithms; the learning objectives and evaluation measures; the reported research solutions; and the class imbalance problem in the presence of multiple classes.},
	language = {en},
	number = {04},
	urldate = {2023-12-18},
	journal = {International Journal of Pattern Recognition and Artificial Intelligence},
	author = {Sun, Yanmin and Wong, Andrew K. C. and Kamel, Mohamed S.},
	month = jun,
	year = {2009},
	pages = {687--719},
}

@article{johnson_survey_2019,
	title = {Survey on deep learning with class imbalance},
	volume = {6},
	issn = {2196-1115},
	url = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0192-5},
	doi = {10.1186/s40537-019-0192-5},
	language = {en},
	number = {1},
	urldate = {2023-12-18},
	journal = {Journal of Big Data},
	author = {Johnson, Justin M. and Khoshgoftaar, Taghi M.},
	month = dec,
	year = {2019},
	pages = {27},
	file = {Full Text:C\:\\Users\\Sandra\\Zotero\\storage\\PTG4QN3E\\Johnson and Khoshgoftaar - 2019 - Survey on deep learning with class imbalance.pdf:application/pdf},
}

@inproceedings{avramidis_multimodal_2023,
	address = {Rhodes Island, Greece},
	title = {Multimodal {Estimation} {Of} {Change} {Points} {Of} {Physiological} {Arousal} {During} {Driving}},
	isbn = {9798350302615},
	url = {https://ieeexplore.ieee.org/document/10193718/},
	doi = {10.1109/ICASSPW59220.2023.10193718},
	urldate = {2023-12-20},
	booktitle = {2023 {IEEE} {International} {Conference} on {Acoustics}, {Speech}, and {Signal} {Processing} {Workshops} ({ICASSPW})},
	publisher = {IEEE},
	author = {Avramidis, Kleanthis and Feng, Tiantian and Bose, Digbalay and Narayanan, Shrikanth},
	month = jun,
	year = {2023},
	pages = {1--5},
}

@article{otter_survey_2021,
	title = {A {Survey} of the {Usages} of {Deep} {Learning} for {Natural} {Language} {Processing}},
	volume = {32},
	issn = {2162-237X, 2162-2388},
	url = {https://ieeexplore.ieee.org/document/9075398/},
	doi = {10.1109/TNNLS.2020.2979670},
	number = {2},
	urldate = {2023-12-20},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Otter, Daniel W. and Medina, Julian R. and Kalita, Jugal K.},
	month = feb,
	year = {2021},
	pages = {604--624},
	file = {Submitted Version:C\:\\Users\\Sandra\\Zotero\\storage\\Q9NBLPMU\\Otter et al. - 2021 - A Survey of the Usages of Deep Learning for Natura.pdf:application/pdf},
}

@inproceedings{lopez-martinez_detection_2019-1,
	address = {Cambridge, United Kingdom},
	title = {Detection of {Real}-{World} {Driving}-{Induced} {Affective} {State} {Using} {Physiological} {Signals} and {Multi}-{View} {Multi}-{Task} {Machine} {Learning}},
	isbn = {978-1-72813-891-6},
	url = {https://ieeexplore.ieee.org/document/8925190/},
	doi = {10.1109/ACIIW.2019.8925190},
	urldate = {2023-12-20},
	booktitle = {2019 8th {International} {Conference} on {Affective} {Computing} and {Intelligent} {Interaction} {Workshops} and {Demos} ({ACIIW})},
	publisher = {IEEE},
	author = {Lopez-Martinez, Daniel and El-Haouij, Neska and Picard, Rosalind},
	month = sep,
	year = {2019},
	pages = {356--361},
	file = {Submitted Version:C\:\\Users\\Sandra\\Zotero\\storage\\U5WEMQZL\\Lopez-Martinez et al. - 2019 - Detection of Real-World Driving-Induced Affective .pdf:application/pdf},
}

@inproceedings{szegedy_going_2015,
	address = {Boston, MA, USA},
	title = {Going deeper with convolutions},
	isbn = {978-1-4673-6964-0},
	url = {http://ieeexplore.ieee.org/document/7298594/},
	doi = {10.1109/CVPR.2015.7298594},
	urldate = {2023-12-20},
	booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Szegedy, Christian and {Wei Liu} and {Yangqing Jia} and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	month = jun,
	year = {2015},
	pages = {1--9},
	file = {Submitted Version:C\:\\Users\\Sandra\\Zotero\\storage\\R37QI3RA\\Szegedy et al. - 2015 - Going deeper with convolutions.pdf:application/pdf},
}

@incollection{fujita_improved_2022,
	address = {Cham},
	title = {An {Improved} {Subject}-{Independent} {Stress} {Detection} {Model} {Applied} to {Consumer}-grade {Wearable} {Devices}},
	volume = {13343},
	isbn = {978-3-031-08529-1 978-3-031-08530-7},
	url = {https://link.springer.com/10.1007/978-3-031-08530-7_77},
	language = {en},
	urldate = {2023-12-20},
	booktitle = {Advances and {Trends} in {Artificial} {Intelligence}. {Theory} and {Practices} in {Artificial} {Intelligence}},
	publisher = {Springer International Publishing},
	author = {Ninh, Van-Tu and Nguyen, Manh-Duy and Smyth, Sinéad and Tran, Minh-Triet and Healy, Graham and Nguyen, Binh T. and Gurrin, Cathal},
	editor = {Fujita, Hamido and Fournier-Viger, Philippe and Ali, Moonis and Wang, Yinglin},
	year = {2022},
	doi = {10.1007/978-3-031-08530-7_77},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {907--919},
	file = {Accepted Version:C\:\\Users\\Sandra\\Zotero\\storage\\6J5NSPB5\\Ninh et al. - 2022 - An Improved Subject-Independent Stress Detection M.pdf:application/pdf},
}

@inproceedings{xie_aggregated_2017-1,
	address = {Honolulu, HI},
	title = {Aggregated {Residual} {Transformations} for {Deep} {Neural} {Networks}},
	isbn = {978-1-5386-0457-1},
	url = {http://ieeexplore.ieee.org/document/8100117/},
	doi = {10.1109/CVPR.2017.634},
	urldate = {2023-12-20},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Xie, Saining and Girshick, Ross and Dollar, Piotr and Tu, Zhuowen and He, Kaiming},
	month = jul,
	year = {2017},
	pages = {5987--5995},
	file = {Submitted Version:C\:\\Users\\Sandra\\Zotero\\storage\\W2JNQFBC\\Xie et al. - 2017 - Aggregated Residual Transformations for Deep Neura.pdf:application/pdf},
}

@article{kingma_adam_2014,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {Adam},
	url = {https://arxiv.org/abs/1412.6980},
	doi = {10.48550/ARXIV.1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2023-12-20},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	year = {2014},
	note = {Publisher: arXiv
Version Number: 9},
	keywords = {FOS: Computer and information sciences, Machine Learning (cs.LG)},
	annote = {Other
Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015},
}
